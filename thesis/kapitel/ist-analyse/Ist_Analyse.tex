\chapter{Ist-Analyse}

Nachdem im letzten Kapitel ein grober Überblick über die bestehende Problemstellung sowie den geplanten Lösungsweg gegeben wurde, folgt ein kurzer Einblick in die bestehenden Technologien um die Sinnhaftigkeit neuerer Technologien zu beleuchten. 

\section{JBoss (Microprofile)}
\begin{itemize}
  \item aktuelle Architektur beschreiben
  \item Hinweis darauf geben, dass Prototyp in der Thesis vereinfacht mit Spring dargestellt wird
  \item jetzt ja fiktiv SpringBoot, hier rein technischer Ist-Stand, Systemarchitektur….
\end{itemize}

Die aktuelle Verarbeitung von Payments innerhalb der Anwendung läuft in Produktion auf vier Instanzen des kommerziellen Applikation-Servers "\emph{JBoss}". Im Development wird hierbei eine Open-Source Variante namens "\emph{Wildfly}" verwendet. In diesen Application Servern werden entsprechende .war Dateien deployed welche den ausführbaren Code der Anwendung beinhalten. Der Application Server bietet dem Server-Teil der Client-Server-Anwendung eine Laufzeitumgebung, in der dieser ausgeführt werden kann. JBoss bietet nun standartisierte Schnittstellen nach dem jeweiligen Java Enterprise Standard um zum Beispiel die Kommunikation mit der Außenwelt zu ermöglichen oder um der Anwendung eine Persistenzschicht zur Verfügung zu stellen. Außerdem laufen die Instanzen im \emph{Microprofile} Modus, der es ermöglicht, bestimmte Konfigurationsparameter auszulagern. So können Applikationen auf unterschiedlichen Systemen deployed werden ohne komplett neu gebaut zu werden (\cite{microprofile}). Um eine gleichmäßige Aufteilung der Last zu gewährleisten, teilt ein so genannter "\emph{Load Balancer}" die eingehenden Nachrichten den entsprechenden Instanzen zu. Jede der vorhandenen Instanzen besitzt eine minimale sowie maximale Anzahl an parallel ausführbaren Prozessen. Diese Angaben werden auch "\emph{max. / min. Poolsize}" genannt. Eine minimale Poolsize muss gegeben sein, um sicherzustellen, dass eine gewisse Grundlast falls nötig sofort bearbeitet werden kann, daher darf diese minimale Anzahl auch nicht Null betragen. Die maximale Poolsize stellt sicher, dass es zu keiner Überlastung des Systems kommt. Wenn eine Instanz bereits mit der maximale Anzahl an Prozessen arbeitet, wird dies dem Loadbalancer signalisiert und dieser teilt der entsprechenden Komponente in diesem Zeitraum keine weiteren Nachrichten mehr zu. Um zu gewährleisten, dass die Nachrichten nicht verloren gehen, werden sie in eine "\emph{Request Queue}" geschrieben, welche lediglich dazu gedacht ist den Overhead abzuspeichern. Wie die Daten im Detail verarbeitet werden, ist für die weitere Betrachtung irrelevant und wird daher nicht weiter erläutert.

\todo{Simples Schaubild einfuegen}
% microprofile: https://access.redhat.com/documentation/en-us/jboss_enterprise_application_platform_continuous_delivery/15/html/configuration_guide/eclipse_microprofile


\section{Probleme}

% https://easy-software.com/de/newsroom/microservices-vs-monolith/
\todo{Quelle einfügen}


\begin{itemize}
  \item Probleme mit aktuellem System (Stichwort Deployment, Wartbarkeit)
  \item Prof. hat extra darauf hingewiesen, dass es nicht nur um die Vorteile der Cloud gehen soll
  \item „Erwartete Probleme in einer Cloud Umgebung“ à aktuell „..starre Hardware und Software- Skalierung…“ unerwartete lastspitzen könnten zu problemen führen, wenn sie die erwartete und verfügbare obergrenze an kapazität übersteigt und wie oben gesagt ineffiziente nutzung von kapital….nochmal mit anderen worten aus 
  \item  1.2 à die auflistung der probleme hier, müssen dann in der zusammenfassung wieder auftauchen und abgehakt werden! Die wollen wir ja auch lösen…
\end{itemize}

Mit der monolithischen Struktur des aktuellen Systems kommt es im Laufe der Zeit zu unterschiedlichen Problemen. Über die Zeit werden Komponenten immer weiter verstrickt, sodass es in einem solchen System auch nach Personalwechsel nicht einfacher wird den Überblick über die gesamt Applikation zu behalten. Dies führt zu fehleranfälligerem Code, welcher sich wiederum negativ auf das Kapital einer Firma niederschlägt. Diese Fehler führen in einem monolithischen System zu einem großräumigen Ausfall der gesamten Applikation, da es keine klare Abgrenzung der einzelnen Komponenten gibt. 

Außerdem laufen die Application Server auf Servern, die (wenn überaupt) eine sehr dünne Abstraktionsschicht bieten ("\emph{starrer Hardware}"). Es ist nicht möglich diese schnell und flexibel zu ersetzen, falls es zu Fehlern in der Produktionsphase kommen sollte. Application Server bringen einen großen Konfigurationsaufwand mit sich, der sich schlecht automatisieren lässt. Man braucht geschultes Fachpersonal um ein solches System zum Laufen zu bekommen.

Eine Skalierung ist mit monolithischen Strukturen nur dadurch möglich, den ausführbare Code auf zusätzlichen Servern zu deployen, dies wird auch \emph{horizontale Skalierung genannt}. Jede dieser Kopien nutzt die gleiche Resourcenanzahl, was es zu einem ineffizienten Design macht, da sie sich nicht dynamisch der gegebenen Last anpassen. Tatsächlich ist ein es jedoch ein viel größeres Problem, wenn ein bereits aufgeteiltes System an seine Kapazitätsgrenze stößt, denn wie bereits erwähnt, besitzten Java-Anwendungen eine relativ lange Initialisierungsphase. Um den heutigen Anforderungen der dynamischen Skalierung gerecht zu werden, werden Resourcen auf Abruf gebraucht. Die Systeme sollen so schnell wie möglich verfügbar sein. 
