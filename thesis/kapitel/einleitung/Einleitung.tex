\chapter{Einleitung}

\section{Überblick}
% \begin{itemize}
%   \item Was gibt es bisher, nur kurz anreissen
%   \item wird im Grundlagen Kapitel tiefgehender behandelt...
% \end{itemize}

Google, Spotify oder Netflix: Immer mehr Unternehmen setzen heutzutage auf Virtualisierungsplattformen. Aber warum sind Technologien, wie zum Beispiel \emph{Docker} als Containerisierungsplattform oder \emph{Docker Swarm} als Orchestrator, so beliebt? In der folgenden Thesis werde ich zunächst erläutern, welche Technik hinter dem Docker-Ökosystem steckt, um anschließend einen Überblick über die verfügbaren Technologien zu geben und diverse Eigenarten näher zu erläutern (was bedeutet es serverless zu deployen etc.). Es wird außerdem einen detaillierten Vergleich zweier moderner Technologien hinsichtlich der Eignung für diese Art von Plattform erarbeitet.


\section{Motivation}
% \begin{itemize}
%   \item Problemstellung kurz beschreiben
%   \item DPS m\"ochte untersuchen ...
%   \item portierung der anwendung in die cloud (amazon)  Problem ist: spring boot anwendung benötigt viel startup-zeit, heute ist die maximale skalierung in produktion vorbestimmt und muss immer vorgehalten werden, alle server sind 24x7x365 aktive und werden eigentlich nur in 1-2h pro tag in den spitzenzeiten ausgelastet… also nicht nur ineffiziente nutzung von hardware und energie sondern auch von kapital. -> hyperscaler geschäftsmodell verspricht abhilfe…
%   \item hier ruhig auch einen Satz zur neuen Sau, die jetzt durchs dorf getrieben wird „new green economy“.. ressourcen sparen um eisbären und gretha thunberg zu retten… energieffizienz…etc bla bla bla sofort-ready vollautomatische Skalierung etc..das sind dann die gganzen Versprechungen der hyperscaler zu der cloud…kannst du hier alle auflisten.  Kunde möchte vorbereitet sein, um ggf. Auflagen der Regulierer zu „green“ erfüllen zu können.
%   \item Welche Erkenntnisse sollen gewonnen werden?
%   \item Kriterienkatalog nennen
% \end{itemize}

Die Idee und die Umsetzung der Arbeit erfolgte in Zusammenarbeit mit der DPS Engineering Gmbh. Hierbei handelt es sich um ein europaweit tätiges Software- und Consultingunternehmen für die Finanz- und Retailbranche. Das Leistungsportfolio umfasst Softwareprodukte und IT-Services für die bekannten Vertreter der deutschen Kreditwirtschaft und des Handels\footnote{Linkedin: \url{https://de.linkedin.com/company/dps_group}}. Die mir zugeteilte Abteilung verwaltet und erweitert eine Plattform zur Abwicklung von Echtzeitüberweisungen. Um diese in Zukunft noch effizienter zu gestalten, möchte sich das Unternehmen von den altbewährten Java-Enterprise Technologien hin zu neuartigen Cloud-Technologien orientieren. Der besondere Fokus hierbei liegt auf der ressourcenschonenderen Arbeitsweise dieser Technologien. Man möchte in Zukunft darauf verzichten stets alle verfügbaren Ressourcen direkt zu verwalten und sich auf das automatische Skalieren dieser Systeme verlassen können. So ist es beispielsweise möglich, dynamisch neue Instanzen benötigter Komponenten zu erzeugen, als sich auf ein starres System zu verlassen, welches fortdauernd mit der gleichen Arbeitslast arbeitet. Dies erspart dem Unternehmen nicht nur Kapital, sondern führt ebenfalls zu einer besseren Klimabilanz (Stichwort "\emph{new green economy}"). Ein Beispiel stellt dabei die Abwicklung von Zahlungsverkehr mit Hilfe von Echtzeitüberweisungen\footnote{Erklärung, siehe Abschnitt \ref{ss:fiktiverWorkflow}} dar, hierbei gilt es hinsichtlich schwankenden Zahlungsverkehrs über einen gewissen Zeitraum das laufende System den Umständen angepasst zu skalieren. Des Weiteren verändert dieser Technologiezweig die Art des produktiven Deployments. Hierbei möchte sich das Unternehmen ebenfalls von den herkömmlichen Application Servern verabschieden, welche im Vergleich einen relativ hohen Wartungsaufwand mit sich bringen. Dabei soll der Übergang zu den Cloud-Technologien erst mittels einer hauseigenen Lösung erfolgen und im Nachgang auf einen Cloud-Provider wie Amazon (AWS) oder Microsoft (Azure) gesetzt werden. Die behandelten Themen dieser Thesis beziehen sich vor allem auf eine beispielhafte Konfiguration einer hausinternen Lösung, um zu analysieren, inwiefern sich dies überhaupt rentiert. 

Neben diesen vor allem an das Kapital der Firma gebundenen Gründen steht auch die Wartbarkeit der implementierten Lösungen im Fokus. Mittels lose gekoppelter Elemente verschwimmt die Grenze zwischen Operations- und Entwicklungsabteilung. Projekte erleben weniger Handoffs zwischen Teams, ein Entwickler betreut ein Projekt bis in die Deploymentphase, was vorher in dem Maße nicht möglich war. Abhängig von Abstraktion der Cloud Technologie ermöglicht die lose Kopplung der Komponenten eine geordnetere Arbeitsweise, die eine verbesserte Codequalität mit sich bringen kann. 

Ein Fokus, welchen ich mir in dieser Thesis im Detail anschauen möchte, betrifft das Start-up-Verhalten einer Anwendung in genau solch einer virtualisierten Umgebung. Denn unter den genannten Effizienzgesichtspunkten möchte man heutzutage auch nötige Ressourcen vor allem auf Anfrage verwenden und nicht mehr rund um die Uhr laufen lassen, selbst wenn dies zu einem gegebenen Zeitpunkt eigentlich gar nicht nötig wäre. Um das Prinzip der Ressourcennutzung auf Anfrage etwas anschaulicher zu gestalten, werde ich eine vereinfachte Kopie einer realen Anwendung vom Unternehmen nachbauen und hinsichtlich der Startzeiten von Container-Instanzen untersuchen. Der Prototyp setzt sich hierbei aus verschiedenen Logikkomponenten zusammen. Diese Komponenten ermöglichen eine detaillierte Analyse des Prototypen hinsichtlich der genannten Effiziensgesichtspunkte und gewährt die Austauschbarkeit bestimmter Module, um verschiedene Technologien gegenüberzustellen.
