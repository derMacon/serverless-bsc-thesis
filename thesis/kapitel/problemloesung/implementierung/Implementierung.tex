\section{Implementierung Prototyp}

Nachdem im letzten Abschnitt auf mögliche Kriterien zur Messung der relevanten Metrikinformationen eingegangen wurde, erfolgt im folgenden eine spezifische Festlegung auf bestimmte Kriterien, welche auf das zu lösende Problem zugeschnitten werden.

\subsection{Komponentenmodell}

\paragraph{Schichtenmodell}
Der Arbeitsfluss der Anwendung wurde in Abbildung \ref{fig:stackOverview} visuell dargestellt. Die unterschiedlichen Komponenten wurden dabei in vier verschiedene Schichten eingeteilt: 

\begin{itemize}
  \item Persistenzschicht (engl. \emph{Persistence layer}): Beinhaltet sämtliche Komponenten, welche für das Abspeichern gegebener Datensätze in dazugehörige Datenbanken zuständig sind. Um Nebenläufigkeit zu ermöglichen wird hier ebenfalls auf Schnittstellen mittels Message-Broker zurückgegriffen. Eine manipulation der Daten findet auf dieser Ebene nicht statt.
  \item Verarbeitungsschicht (engl. \emph{processing layer}): Beinhaltet sämtliche Komponenten, welche für die direkte Verarbeitung der Business-Logik zuständig sind. Die Kommunikation zwischen den Komponenten findet über eine REST-Schnittstelle sowie einen Message-Broker statt. Der Message-Broker stellt hierbei vorallem eine nebenläufige Verarbeitung der konsumierenden Komponenten sicher. Allerdings bietet dieser ebenfalls die Schnittstelle zur Skalierungsschicht (engl. \emph{scaling layer}).
  \item Skalierungsschicht (engl. \emph{scaling layer}): Beinhaltet sämtliche Komponenten zum Skalieren der konsumierenden Komponenten. Hierbei wird auf eine universelle Schnittstelle des Message Broker zurückgegriffen um entsprechende Metriken abzugreifen, die für die Evaluierung hinterlegter Regeln zur Skalierung verwendet werden. Ansonsten wird in Komponenten dieser Schicht das Zeitverhalten des Initialisierungsprozesses der konsumierenden Komponenten überwacht und an Schnittstellen der Persistenzschicht weitergeleitet.
  \item Monitoring Ebene: Diese Schicht besteht aus einer einzigen Komponente, deren einzige Aufgabe es ist erhaltene Daten visuell darzustellen. Um einen zeitlichen Überblick zu geben, werden die Daten intern vom Werkzeug gespeichert. Da es sich um lokal verwaltete Datensätze handelt, die für den Rest der Applikation keinerlei Bedeutung darstellen wurde verzichtet eine Lösung zu finden, in der diese ebenfalls in einer Komponente der Persistenzschicht unterzubringen.
\end{itemize}

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\linewidth]{kapitel/problemloesung/implementierung/_img/overview-bw}
	\caption[Komponenten-Stack im Überblick]{Komponenten-Stack im Überblick}
	\label{fig:stackOverview}
\end{figure}



\paragraph{Komponenten im Überblick}
Es folgt eine kurze Zusammenfassung der Funktionalität sowie der Anforderungen an die jeweligen Komponenten.

\subparagraph{Input}
Um es dem Benutzer zu ermöglichen gezielte Messwerte zu erfassen, wird eine REST-Schnittstelle vom System bereitgestellt. Es ist zwar möglich, dass der Benutzer selbstständig Anfragen für diese Schnittstelle generiert und absendet, es ist allerdings beabsichtigt, dass der Benutzer auf vordefinierte Skript oder eine entsprechende Benutzeroberfläche zurückgreift. Die Benutzeroberfläche ist sehr funktional gehalten, sodass es zwar möglich ist hierüber Anfragen an das System zu stellen, dennoch empfiehlt sich gerade für komplexere Anfrageszenarien der Gebrauch von bereitgestellten Bash-Skripten. Bezüglich der Skripte gibt es ebenfalls eine diverse Abstraktionsschichten. So ist es zum Beispiel möglich mittels einer definierten Grammatik Anforderungen zu definieren welche sich beliebig kombinieren lassen. Hierzu wurden mehrere vordefinierte Dateien angelegt, welche über ein entsprechendes Skript an das Backend geschickt werden kann. Allerdings gibt es Skripte die auf diesem Prozess aufsetzen, sodass der Endbenutzer sich hiermit nicht auseinandersetzen muss. 


\subparagraph{Supplier}
Diese Komponente ist in der Lage die vereinfachten Anfragen des Benutzers zu interpretieren und in Nachrichten umzuwandeln, die vom System verarbeitet werden können. Hierbei werden bereits an dieser Stelle diverse Informationen an die ursprüngliche Nachricht angehängt um im späteren Verlauf entsprechende Metriken zu berechnen. Außerdem erfolgt eine erste Kommunikation mit der Persistenzschicht, in der die übersetzten Benutzeranfragen abgespeichert werden. Hierbei wird direkt auf die Datenbank zugegriffen, da es im System stets nur diese eine Instanz des \emph{Suppliers} gibt. Zwar unterstützt die verwendete Postgres-Datenbank mehrere Klienten zur gleichen Zeit, nativ ist diese Anzahl jedoch begrenzt und muss angemessen konfiguriert werden. Desweiteren stellt die Supplier-Komponente zwei Modi hinsichtlich der Geschwindigkeit in der Nachrichten an den Broker übermittelt werden. So ist es zum Beispiel möglich Nachrichten über einen gewissen Zeitraum hinweg abzuschicken oder aber eine Transaktion zu bilden in der alle auf einmal geschickt werden.


\subparagraph{Broker}
Dieser Activemq Broker stellt die Funktionalität bereit Nachrichten an mehere Konsumenten zu vermitteln. Dabei gibt es zwei Betriebsmodi, einmal das Arbeiten mit einer \emph{topic} sowie mit einer \emph{queue}. Eine Topic stellt ein \emph{Publisher-Subscriber-Muster} bereit in dem alle eingehenden Nachrichten an alle eingeschriebenen Konsumenten verschickt werden \todo{Quelle verlinken}. Demgegenüber steht eine \emph{queue} (Warteschlange), welche eingehende Nachrichten lediglich an einen einzelnen Konsumenten übermittelt, wobei er hierbei als eine Art Loadbalancer agiert. Bevor die Nachrichten jedoch aus einer der beiden Datenstrukturen entfernt wird, muss der betreffende Konsument eine \emph{Acknowledgement-Nachricht} an den Broker schicken um zu signalisieren, dass die Nachricht nicht nur angenommen sondern auch korrekt verarbeitet werden konnte. Es gilt auch noch hervorzuheben, dass die eingeschriebenen Konsumenten bei neuen Nachrichten stets benachrichtigt werden und es clientseitig keine Logik benötigt um zum Beispiel event- oder intervallbasiert eine Abfrage an den Broker zu steuern. Da diese Komponente ebenfalls vom ... \emph{Prometheus erklären, Links raussuchen}. 


\subparagraph{Consumer}
Die konsumierenden Komponenten können beliebig skaliert werden und implementieren den in Abschnitt \ref{ss:fiktiverWorkflow} definierten Workflow. Hierbei wird auf diverse Libraries zurückgegriffen, wobei die restliche Logik eher schlicht gehalten wurde. Die Komponenten kommunizieren lediglich über den Message-Broker mit dem Nachrichten-Supplier und über einen weiteren Nachrichten-Broker mit der Persistenzschicht um die extrahierten Elemente abzulegen.


\subparagraph{Prometheus}
"Bei diesem Projekt handelt es sich um ein \emph{Open Source} auf Metriken basierendes Monitoring System" \cite{oreillyPrometheus}. Es ist möglich über eine definierte Anfragensprache Daten Dritter zu verarbeiten. Diese Daten können über ein einfaches Textformat von den Komponenten ausgegeben werden. Es ist möglich dieses Textformat händisch zu schreiben, allerdings wird in der Praxis vermehrt auf Libraries, die auf den Client zugeschnitten wurden, gesetzt. Prometheus ist unter der Apache 2.0 Lizenz veröffentlicht \footnote{https://github.com/prometheus/prometheus}, und ist primär in der Programmiersprache Go implementiert worden. Das Scrapen der Metriken wird von der Prometheus Komponente selbst durchgeführt, die zu überwachenden Komponenten müssen sich selbst nicht darum kümmern Daten an Prometheus zu übermitteln.

\todo{checken ob Figure am Ende immer noch nicht unter die folgenden Absatz auf Seite passt, ggf. aendern}
\begin{figure}[ht!]
	\centering
	\includegraphics[width=.8\linewidth]{kapitel/problemloesung/implementierung/_img/alert-man-p307}
	\caption[Alert Manager - Übersicht]{Alert Manager - Übersicht \cite[Seite~307]{oreillyPrometheus}}
	\label{fig:alertManOverview}
\end{figure}

\subparagraph{Alert Manager}
"Unter \emph{Alerting} versteht man das in Kenntnis setzen eines Admins, wenn es im System zu Problemen kommen sollte" \cite[Kapitel~18]{oreillyPrometheus}. Prometheus bietet hierbei die Möglichkeit mittels der funktionalen Anfragesprache \emph{PromQl} diverse Bedingungen zu definieren unter denen dies geschehen soll. Da es in einer produktiven Containerumgebung durchaus vorkommen kann, dass mehrere Prometheus-Instanzen parallel arbeiten, wurde das Benachrichtigen in eine weitere Komponente (den \emph{Alert Manger}) ausgelagert. Dieser synchronisiert, sammelt und gruppiert die Alerts der verschiedenen Prometheus-Instanzen und sendet Benachrichtigungen an definierte Nachrichtenkanäle, die sich zum Beispiel aus einem Emailpostfach, einer Pagernachricht oder Chatnachricht auf Plattformen wie zum Beispiel Slack zusammensetzen können (siehe Abbildung \ref{fig:alertManOverview}).


\subparagraph{Scaler Proxy}
Diese Komponente bietet eine REST-Schnittstelle, welche im Alert-Manager hinterlegt wird. Sobald eine der Regeln anschlägt wird der Aufruf an diese Komponente weitergeleitet. Im Endeffekt dient diese Kompoonente nur als Proxy-Service, da sie diese Nachricht lediglich an eine weitere Komponente weiterleitet. In einer produktiven Umgebung würde diese Komponente komplett enfallen, da es möglich ist den Alert-Manager derartig zu konfigurieren, dass er direkt die öffentlichen Schnittstellen der Scaler-API anspricht. Es wurde sich dennoch für das Zwischenschalten eines solchen Proxy-Services entschieden um genauere Messewerte zu erhalten. Gerade hinsichtliche der Initialisierungsphasen von Containern ist es angebracht so kurz vorher wie möglich einen Timestamp zu setzen. Da es nicht möglich ist direkt in die Konfiguration der Scaler-Api einzugreifen ist diese Lösung der nächstbeste Ansatz. Sobald eine Skalierungsanfrage weitergeleitet wurde, wird diese noch unbeantwortete Anfrage intern in einer Datenstruktur abgelegt. Sobald ein entsprechender Container komplett initialisiert wurde, ruft dieser eine weitere Schnittstelle des Proxy-Services auf. Daraufhin wird ein \emph{Acknowledgement-Timestamp} in der hinterlegten Anfrage gesetzt und an die Persistenzschicht weitergeleitet. 

Außerdem bietet diese Komponente die Möglichkeit für den Benutzer direkt Exemplare eines Consumers hochzufahren. Die Verwendete Schnittstelle dient als Umgehung des herkömmlichen Programmflusses und wird zur Generierung der Skalierungsschichtenunabhängigen Metrikberechnung verwendet (siehe Abschnitt \ref{par:specContainer}). Über dedizierte Endpunkte können diese Metriken als .csv Datei ausgelesen werden. 


\subparagraph{Scaler}
"\emph{Das Ziel des Docker Scaler-Projekts ist es eine REST-Http-Schnittstelle zum Skalieren von Services und Nodes bereitzustellen}"\cite{docker-scaler}. Außerdem werden mit jeder Skalierungsanfrage Statusinformationen über die aktuelle sowie zukünftige Anzahl von Nodes des zu skalierenden Services zurückgegeben, die es dem proxy-Service ermöglichen davon ausgehend einen Skalierungsstop für neue Anfragen beizubehalten oder aufzuheben. Dieser ist nötig damit das System keine weiteren Skalierungen vornimmt, wenn bereits welche am laufen sind.


\subparagraph{Grafana}
"Wenn es zum Alert durch den Alert Manager kommt, wird in einer Produktivumgebung der Erste Schritt sein die Performanz des Systems durch dedizierte Dashboard zu überprüfen" \cite[Kapitel~6]{oreillyPrometheus}. Grafana ist ein Werkzeug, das dies über eine Weboberfläche direkt im Browser ermöglicht. Es bietet die Möglichkeit Graphen, Tabellen und weitere Visualisierungskomponenten zu erstellen um zum Beispiel die Latenzzeit oder CPU Auslastung zu überprüfen. Diese Metriken können für das ganze Sytem oder nur einen Teil generiert werden. Es ist das bevorzugte Visualisierungswerkzeug für Prometheus, bietet allerdings ebenfalls Unterstützung für verschiedene weitere Systeme wie zum Beispiel \emph{Graphite}, \emph{Elasticsearch} oder \emph{PostgreSQL}.


\subparagraph{Mock scaler api}
Diese Komponente ist nicht Kernbestandteil des Komponenten-Stacks. Während der Entwicklungszeit dient sie dazu die Scaler-Api zu emulieren. So ist es zum Beispiel möglich lokal eine Instanz des Scaler-Proxy Projekts in einer beliebigen IDE als Standard Spring Projekt auszuführen. Sämtliche Skalierungs-Anfragen können von dieser Komponente angenommen werden, da sie auf dem gleichen Port wie der "\emph{echte}" Scaler läuft, wobei sie dabei ebenfalls in der Lage ist diverse Rückgabenachrichten an den Klienten zu übergeben.



\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{kapitel/problemloesung/implementierung/_img/grafana-dashboard-01}
	\caption[]{Grafana Dashboard}
	\label{fig:grafanaOverview}
\end{figure}




\subsection{Node.js}
\subsection{Spring Boot}

\section{Implementierung mittels Containerisierungsplattform}
\subsection{Container Lifecycle}
\begin{itemize}
  \item Auf verschiedene Schichten eingehen
  \item Auf Ergebnisse beziehen
\end{itemize}
\subsection{Docker Swarm}

\begin{itemize}
  \item Prototypen im Detail erlaeutern
\end{itemize}


\renewcommand\theadalign{bc}
\renewcommand\theadfont{\bfseries}
\renewcommand\theadgape{\Gape[4pt]}
\renewcommand\cellgape{\Gape[4pt]}


\begin{lstlisting}[language=bash]
cat .env

# qbn: queue bound (level) n
# cbn: container bound (level) n

QB0=15
QB1=30
QB2=100
CB0=1
CB1=5
CB2=10
CB3=30
\end{lstlisting}


\begin{tabularx}
  {\textwidth}
  { X | X | X | X | X }
  % {p{0.2\textwidth} | X | X | X | X }
  % {
  %   |p{0.32\textwidth-2\tabcolsep}
  %   |p{0.17\textwidth-2\tabcolsep}
  %   |p{0.17\textwidth-2\tabcolsep}
  %   |p{0.17\textwidth-2\tabcolsep}
  %   |p{0.17\textwidth-2\tabcolsep}|}
  % }
  \toprule
      \centering \hspace{4mm} \uline{QL3} \newline \footnotesize \textit{QB2 \textless{} MC} 
    & \centering \hspace{4mm} UP \newline \footnotesize \textit{abs(CB0 -- CB3)} 
    & \centering \hspace{4mm} UP \newline \footnotesize \textit{abs(CB1 -- CB3)} 
    & \centering \hspace{4mm} UP \newline \footnotesize \textit{abs(CB2 -- CB3)} 
    & \centering \hspace{4mm} OK \newline -- 
    \tabularnewline
  \hline
      \centering \hspace{4mm} \uline{QL2} \newline \footnotesize \textit{QB1 \textless{} MC $\leq$ QB2} 
    & \centering \hspace{4mm} UP \newline \footnotesize \textit{abs(CB0 -- CB2)} 
    & \centering \hspace{4mm} UP \newline \footnotesize \textit{abs(CB1 -- CB2)} 
    & \centering \hspace{4mm} OK \newline -- 
    & \centering \hspace{4mm} DOWN \newline \footnotesize \textit{abs(CB2 -- CB3)} 
    \tabularnewline
  \hline
      \centering \hspace{4mm} \uline{QL1} \newline \footnotesize \textit{QB0 \textless{} MC $\leq$ QB1} 
    & \centering \hspace{4mm} UP \newline \footnotesize \textit{abs(CB0 -- CB1)} 
    & \centering \hspace{4mm} OK \newline -- 
    & \centering \hspace{4mm} DOWN \newline \footnotesize \textit{abs(CB1 -- CB2)} 
    & \centering \hspace{4mm} DOWN \newline \footnotesize \textit{abs(CB1 -- CB3)} 
    \tabularnewline
  \hline
      \centering \hspace{4mm} \uline{QL1} \newline \footnotesize \textit{QB0 \textless{} MC $\leq$ QB1} 
    & \centering \hspace{4mm} UP \newline \footnotesize \textit{abs(CB0 -- CB1)} 
    & \centering \hspace{4mm} OK \newline -- 
    & \centering \hspace{4mm} DOWN \newline \footnotesize \textit{abs(CB1 -- CB2)} 
    & \centering \hspace{4mm} DOWN \newline \footnotesize \textit{abs(CB1 -- CB3)} 
    \tabularnewline
  \hline
      \centering \hspace{4mm} \uline{QL0} \newline \footnotesize \textit{QB0 == MC} 
    & \centering \hspace{4mm} OK \newline -- 
    & \centering \hspace{4mm} DOWN \newline \footnotesize \textit{abs(CB0 -- CB1)} 
    & \centering \hspace{4mm} DOWN \newline \footnotesize \textit{abs(CB0 -- CB2)} 
    & \centering \hspace{4mm} DOWN \newline \footnotesize \textit{abs(CB0 -- CB3)} 
    \tabularnewline
  \hline
    & \centering \hspace{4mm} \uline{CL0} \newline \footnotesize \textit{CB0 == MC} 
    & \centering \hspace{4mm} \uline{CL1} \newline \footnotesize \textit{CB0 \textless{} MC $\leq$ CB1} 
    & \centering \hspace{4mm} \uline{CL1} \newline \footnotesize \textit{CB1 \textless{} MC $\leq$ CB2} 
    & \centering \hspace{4mm} \uline{CL1} \newline \footnotesize \textit{CB2 \textless{} MC $\leq$ CB3} \tabularnewline
  \bottomrule
\end{tabularx}

\section{Implementierung Lasttest}
\subsection{Timeline}
\subsection{Testbedingungen}
\begin{itemize}
  \item Kommt in den Anhang
  \item hat Prof. zwar als eigenes Kapitel erwaehnt, bin mir aber nicht sicher ob das wirklich noetig ist
  \item auf welcher Hardware werden Tests durchgefuehrt?
  \item chaos monkey / Stoerfaelle erlaeutern
\end{itemize}

\begin{table}
  \centering
  \caption{Server Specs}
  \bigskip
  \begin{tabular}{ c l }
    \toprule
    Prozessor & Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz \\
    \midrule
    Kerne & 6 Prozessoren á 16 Kerne \\
    \midrule
    RAM & 16 GB \\
    \midrule
    Storage & 150 GB \\
    \bottomrule
  \end{tabular}
\end{table}


% \begin{filecontents*}{test.csv}
%   a,b,c,d
%   1,4,5,1
%   2,3,1,5
%   3,5,6,1
%   4,1,4,9
%   5,3,4,7
%   \end{filecontents*}


\begin{tikzpicture}
\begin{axis}[xlabel={Container Anzahl}, ylabel={Startzeit}]
\addplot table [x=id, y=value, col sep=comma] {test.csv};
\addlegendentry{Spring Boot}
\addplot table [x=id, y=value, col sep=comma] {test2.csv};
\addlegendentry{Node.js}
\end{axis}
\end{tikzpicture}

% \begin{filecontents}{\jobname Data.csv}
%   Jahr;CD;MC
%   1990;298;450
%   1991;330;370
%   1992;420;373
%   1993;485;345
%   1994;650;355
%   1995;710;275
%   1996;770;225
%   1997;750;170
%   1998;815;155
%   1999;925;125
%   2000;926;75
%   2001;890;50
%   2002;825;30
%   2003;750;20
%   2004;775;12
%   2005;700;7
%   2006;620;5
%   2007;515;5 
%   \end{filecontents}
%   \documentclass[paper=a4,12pt,version=last]{scrartcl}
%   \usepackage{pgfplots}
   
%   \begin{document}
%   \begin{tikzpicture}
%         \begin{axis}[ymin=0,
%   %         xtick={1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007},
%            x tick label style={/pgf/number format/1000 sep=},
%            xlabel={Jahr},
%            y tick label style={/pgf/number format/1000 sep=},
%            ylabel={in Mio. Stück}
%            ]
   
%      \addplot table [y=CD,col sep=semicolon]  {\jobname Data.csv};
%      \addlegendentry{CD}
%      \addplot table [y=MC,col sep=semicolon]  {\jobname Data.csv};
%      \addlegendentry{MC}
  
%         \end{axis}
%      \end{tikzpicture}


\section{Implementierung Visualierung und Monitoring zur Unterst\"utzung der Auswertung}


% \begin{lstlisting}[style=javaStyle,float,caption=Bank - Konstruktor,label=lst:bank_konstruktor]
\begin{lstlisting}[style=javaStyle]
  // standard constructor 
  public Bank(int playerCnt) {
      this.entries = new Entry[playerCnt];
      this.bankSize = playerCnt;
          this.rand = new Random();
  }
  
  // testing constructor - no fileIO
  public Bank(Entry[] entries, Random pseudoRandom) {
      this.entries = entries;
      this.rand = pseudoRandom;
      this.bankSize = entries.length;
  }
  
  // testing constructor - with fileIO
  public Bank(String preallocation, List<Player> players, Random rand) {
      assert null != preallocation && null != players && null != rand;
      this.bankSize = players.size();
      this.entries = new Entry[this.bankSize];
      if (0 < preallocation.length()) {
          String[] singleEntries = preallocation.split(SEPERATOR_STRING_REPRESENTATION);
          int offset = this.bankSize - singleEntries.length;
          for (int i = singleEntries.length - 1; i >= 0; i--) {
              this.entries[i + offset] = new Entry(singleEntries[i], players);
          }
      }
  }
\end{lstlisting}


\begin{lstlisting}[style=bashStyle]
#!/bin/bash

# Add two numeric value
((sum=25+35))

#Print the result
echo $sum
\end{lstlisting}