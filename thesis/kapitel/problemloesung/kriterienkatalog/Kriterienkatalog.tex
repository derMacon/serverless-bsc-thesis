\section{Bestimmung von Daten zur Messung des Start-up-Verhaltens von Containern}

Nachdem im letzten Abschnitt auf mögliche Kriterien zur Messung der relevanten Metrikinformationen eingegangen wurde, erfolgt im Folgenden eine spezifische Festlegung auf bestimmte Kriterien, welche auf das zu lösende Problem zugeschnitten werden.

% \subsection{Kriterienkatalog}
% \begin{itemize}
%   \item Vorallem Skalierbarkeit und Performance
%   \item Transaktionen - Durchsatz wichtig
%   \item Deployment egal, da bereits im Container deployed wird
%   \item Generell sagen, warum einige Aspekte egal sind
%   \item Wartbarkeit nicht so wichtig
%   \item Ressourcennutzung
%   \item St\"orungsf\"alle (Chaos Monkey)
%   \item Non Functionals - Kai hat PDF geschickt
% \end{itemize}

\subsection{Leistungsfähigkeit}
Die wesentlichen Metriken stellen hierbei der Datendurchsatz sowie die Latenzzeit dar. Die Latenzzeit sollte die komplette Pipeline abdecken, also vom Dateneingang durch den Benutzer bis hin zur tatsächlichen Speicherung der Daten in der Persistenzschicht. Die gesamte Strecke lässt sich allerdings auch in noch kleinere Abschnitte unterteilen, um bei unerwarteten Werten festzustellen, an welcher Stelle genau es zu einem Engpass kommt. Der Prototyp soll Daten des Benutzers annehmen, daraus Nachrichten generieren und diese an entsprechende Konsumenten weiterleiten. Die Unterteilung der gesamten Pipeline sollte hierbei zumindest in zwei Abschnitten erfolgen.

\begin{itemize}
  \item Hierbei ist vor allem von Interesse, ob sich der Zeitrahmen vom Eingang der Daten bis zum Erhalt der Daten durch die Konsumenten während der Skalierungstests in irgendeiner Weise verändert. Dies wird jedoch nicht erwartet, da beide Arten von Testläufen auf dieselbe Eingangsschnittstelle zurückgreifen. Eine Veränderung deutete auf ein tieferliegendes Problem bei der Orchestrierung des Stacks hin.
  \item Außerdem sollte der Zeitrahmen vom Erhalt der Daten durch die Konsumenten bis hin zur Interaktion mit der Persistenz-Schicht gesondert betrachtet werden. Dieser Abschnitt stellt den variablen Teil der Pipeline dar und ist von größtem Interesse. 
\end{itemize}

Auf Werkzeuge wie zum Beispiel \emph{Gatling}\footnote{\url{https://gatling.io/}} oder \emph{JMeter}\footnote{\url{https://jmeter.apache.org/}} muss hierbei verzichtet werden, da diese nicht in der Lage sind in die Pipeline einzugreifen um die einzelnen Abschnitte gesondert betrachten beziehungsweise messen zu können. Die Metriken müssen sowohl mithilfe der kompilierten Arbeitsversion als auch der Skript-Version generiert werden um eine Gegenüberstellung durchführen zu können. Hierbei sollte es außerdem möglich sein, den zeitlichen Verlauf der Metriken darzustellen um nachvollziehen zu können, ob es Phasen gibt, in denen die Bearbeitung von dem berechneten Durchschnittswert abweicht. Je nach Stärke der Abweichung gilt es zu evaluieren, ob zusätzliche statistische Kenngrößen diesbezüglich berechnet werden sollten. Ein weiteres mögliches Kriterium wäre in diesem Zusammenhang zum Beispiel die Standardabweichung. Da die Latenzzeit stark mit dem eigentlichen Datendurchsatz zusammenhängt, ist es nicht nötig, diese noch einmal gesondert zu berechnen um Redundanz zu vermeiden.


\subsection{Skalierbarkeit}
Da es sich bei dem Projekt um eine containerisierte Cloud-Anwendung handelt, muss hierbei eine \emph{vertikale Skalierung} stattfinden. Um möglichst akkurate Werte zu erreichen, müssen die zu skalierenden Container in engem Austausch mit dem System stehen. Es muss festgehalten werden, wann genau der Befehl zum Skalieren getätigt wird und wann die Initialisierungsphase eines entsprechenden Containers abgeschlossen wurde. Als vollkommen initialisiert gilt ein Container, wenn neben dem eigenen Filesystem auch sämtliche relevante Kommunikationsschnittstellen gestartet sind und benötigte Datenverbindungen bestehen. Darüber hinaus sei noch erwähnt, dass die erhobenen Metriken jeweils getrennt pro Backend-Technologie erhoben werden sollen, damit eine Gegenüberstellung gewährleistet werden kann.

Bezüglich der Skalierung gilt, dass insbesondere ein vorausschauendes Regelmodell entworfen werden soll, das die Container stufenweise erst dann skaliert, wenn eine Vielzahl von Nachrichten eine gewisse Latenzzeit überschreiten oder der Message Broker (Definition siehe \ref{ss:broker} \nameref{ss:broker}) eine entsprechende Menge an unbeantworteten Nachrichten hält. Hierbei soll eine sinnvolle Festlegung von Grenzwerten gefunden werden. Um im Nachhinein genaue Vergleichswerte ermitteln zu können, sollen lediglich die Container der Konsumenten-Instanzen skaliert werden. Die restlichen Stackkomponenten laufen jeweils als eine Singleton-Instanz. Der Skalierungsprozess soll sowohl mit eingegangenen Nachrichten, als auch durch spezifische Benutzeranfragen gestartet werden können. Diese Unterteilung soll in den persistierten Datensätzen erkennbar sein.

Die mit eingegangenen Nachrichten generierten Skalierungen sollen anhand des festgelegten Stufenmodells ausgegeben werden. Hierbei wird der Durchschnitt aller in dieser Stufe / Gruppe enthaltenen Skalierungen gebildet und dargestellt. Es soll allerdings ebenfalls möglich sein, die durchschnittlichen Werte sowohl für einzelne Containeranzahlen als auch für alle durchlaufenen Skalierungen geben. Ähnlich zu den Metriken der \emph{Leistungsfähigkeit} gilt, sie sollen ebenfalls zeitlich aufbereitet werden. Falls sich hierbei Anomalien hinsichlich der zeitlichen Entwicklung abzeichnen lassen, können zusätzliche statistische Metriken hinzugezogen werden. Es könnte beispielsweise von Interesse sein, ob es bestimmte Zeitpunkte gibt, in denen die Skalierungszeit im Vergleich zum Gesamtdurchschnitt deutlich kürzer beziehungsweise länger dauert. Hierbei lässt sich zum Beispiel ermitteln, wie häufig diese Abweichungen auftreten, ob sie immer zum gleichen Zeitpunkt während einer Skalierungsphase auftreten und ob wie ausgeprägt diese Abweichungen ist.

\subsection{Zusätzliche Kriterien}
Um einen funktionsfähigen Prototypen erstellen zu können, der die beiden wesentlichen Kenngrößen überhaupt erheben kann, müssen bereits viele der im vorherigen Abschnitt erläuterten Kriterien gelten. Um skalierte Konsumenten zu ermöglichen, sind die beiden Aspekte des ISO-Hauptkriterium der "\emph{Kompatibilität}" der Nebenläufigkeit (\emph{Ko-Existenz} sowie \emph{Interoperabilität} siehe Abschnitt \ref{ss:kompatabilitaet} \nameref{ss:kompatabilitaet}) unabdingbar. Ein funktionierender Prototyp zeigt hierbei auf, dass die Aspekte zwangsweise erfüllt sein müssen. Diese werden daher nicht erneut gesondert betrachtet. Auch das Kriterium der "\emph{Zuverlässigkeit}" (siehe Abschnitt \ref{ss:zuverlaessigkeit} \nameref{ss:zuverlaessigkeit}) wird durch eine funktionierende Implementierung bereits in Teilen erfüllt, da es beim genutzten Orchestrator zum gegenwärtigen Zeitpunkt keine Möglichkeit für eine definierte Ausführungsreihenfolge gibt. Die Komponenten müssen im Zweifelsfall mehrfach starten um eine Verbindung aufbauen zu können. Sämtliche Anforderungen bezüglich des Prototypen, der Orchestrierungsplattform, des Lasttests sowie deren Visualisierung wurden im letzten Abschnitt (siehe \ref{sec:anforderungProto} \nameref{sec:anforderungProto}) ausreichend detailliert erläutert und können komplett übernommen werden. Für die Umsetzung dieser Anforderungen siehe Abschnitt \ref{sec:implementierung} \nameref{sec:implementierung}.

\subsection{Zusammenfassung}
Der Übersichtlichkeit halber hier noch einmal eine stichwortartige Zusammenfassung der zu ermittelnden Metriken hinsichtlich der betrachteten Kriterien:

\begin{itemize}
  \item Latenzzeit im Durchschnitt sowie als zeitliche Historie
  \begin{itemize}
    \item Abschnitt \emph{vor} Datenaufnahme gesondert betrachten
    \item Abschnitt \emph{nach} Datenaufnahme gesondert betrachten
    \item Gesamte Pipeline betrachten
  \end{itemize}
  \item Skalierungsdauer jeweils pro verwendeter Backend-Technologie festzuhalten
  \begin{itemize}
    \item Skalierung anhand eingehender Nachrichten mithilfe Stufenmodell
    \item Skalierung mittels direkter Benutzeranfrage (ohne eingehende Nachrichten)
    \item Metriken als Datensätze in einer Datenbank hinterlegt
    \item Durchschnittliche Startzeit pro Containeranzahl 
    \item Durchschnittliche Startzeit pro Skalierungsstufe 
    \item Gesamtdurchschnittliche Startzeit als einzelner Messwert
    \item Metriken zeitlich visualisieren
  \end{itemize}
\end{itemize}