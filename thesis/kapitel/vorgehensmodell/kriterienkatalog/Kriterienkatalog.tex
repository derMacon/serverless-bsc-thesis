\section{Anforderungen an Daten zur Messung des Startup-Verhaltens von Containern \checkmark}
\label{sec:startupAnforderungen}

% \begin{itemize}
%   \item Problem reduzieren
%   \item Messkriterien festlegen
%   \item Quellen finden
%   \item hier nur theoretisch schwafeln über einen kriterienkatalog und die möglichen „Messwerte“, die man ggf. braucht -> in Kap. 5 dann den Kriterienkatalog konkret aufstellen
% \end{itemize}

Der Fokus des Projekts liegt auf der Ermittlung der Cloudfähigkeit der unterschiedlichen System-Komponenten. Um dies festzustellen, muss im Vorwege eine Klassifizierung der Anforderungen stattfinden. Anhand dieser Klassifizierung werden die relevanten Messdaten beziehungsweise Metriken ermittelt. Die internationale Organisation für Normung (kurz \emph{ISO}) verfasste für die generelle Klassifizierung von qualitativen Anforderungen an Softwareprodukte bereits einen ausführlichen Kriterienkatalog, welcher im Folgenden als Grundlage für die beschriebene Auswahl verwendet wird (siehe ISO/IEC 25010:2011 \cite{iso25010}, fig. \ref{fig:iso25010}). 

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\linewidth]{kapitel/vorgehensmodell/kriterienkatalog/_img/iso25010}
	\caption[iso25010]{ISO 25010}
	\label{fig:iso25010}
\end{figure}

Die ISO-Norm 25010 besteht aus acht Hauptkategorien und 31 Unterkriterien, wobei lediglich die erste Hauptkategorie der "\emph{Funktionalität}" dabei als \emph{funktionale Qualitätseigenschaft} (engl. "\emph{functional requirement}") auftritt. Die restlichen Hauptkriterien lassen sich der Kategorie der \emph{Non-Functional requirements} zuordnen. Diese Unterscheidung dient als eine erste Abstraktionsschicht. Functional requirements beschreiben hierbei die Korrektheit des Produktes \cite[Seite~335]{continuous-delivery}. "\emph{Functional requirements specifies a function that a system or system component must
be able to perform}" \cite[Seite~19]{eide-requirements}. So lässt sich feststellen ob die Applikation den inhaltlichen Ansprüchen, sowohl aus technischer als auch aus Unternehmenssicht, genügen. Hierbei wird auf eine Vielzahl unterschiedlicher Tests zurückgegriffen, welche sich auf breit gefächerte Abstraktionstiefen etc. beziehen lassen (siehe \ref{fig:testing-quad}). Je nach Teilbereich lassen sich hierbei einzelne Gebiete automatisiert oder mittels anderweitiger Werkzeuge testen. Diese Tests sind in einem System in Produktion unabdingbar, für die Messdatenerhebung zur Beurteilung der Cloudfähigkeit können diese allerdings vernachlässigt werden. 

Zur Eingrenzung der Anforderungen an die Messdaten sind primär die \emph{Non-Functional Requirements} von Bedeutung. Sie beschreiben nicht \emph{was} vom System geleistet werden muss, sondern \emph{wie} dies geschehen soll, deshalt werden die Kriterien unter anderem auch \emph{system-quality attributes} genannt \cite[Seite~335]{continuous-delivery}. Im Folgenden werden die für das Projekt relevanten Kriterien zusammengefasst dargestellt.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{kapitel/vorgehensmodell/kriterienkatalog/_img/agile-testing-quadrants}
	\caption[Agile Testing Quadrants]{Agile Testing Quadrants}
	\label{fig:testing-quad}
\end{figure}




\subsubsection{Leistungsfähigkeit \checkmark}
% https://www.dotnetcurry.com/project-management/1462/non-functional-requirements-nfrs
% \begin{itemize}
%   \item "Performance of a product or an app defines how a product/app is performing or behaving as compared to its expected behavior"
%   \item Reaktionszeiten, wie schnell ist app wenn User interagiert
%   \begin{itemize}
%     \item eng verwand \emph{Latenz / Delay}, wie lange darf ein User max. warten müssen (Threshold ist die Reaktionszeit)
%     \item typischerweise pro Screen gesetzt, kann aber auch auf die Masse bezogen werden (bspw. 80 Prozent der Interaktionen haben eine Reaktionszeit von max. 3 Sekunden)
%   \end{itemize}
%   \item Durchsatz: Anzahl der Daten, welche die Applikation handlen kann
%   \begin{itemize}
%     \item kann sich sowohl auf Benutzeranfragen, db Anfragen, API calls etc. beziehen
%     \item Durchsatzziele als Teil der Anforderungsanalyse
%     \item werden mittels Performance / Load Testing validiert
%   \end{itemize}
%   \item tools wie gatling / Jmeter fuer diesen Usecase unpassend, da nicht die Api Anfrage sondern nur die Hochfahrzeit gemessen werden soll
%   \item 
% \end{itemize}

\emph{"Performance of a product or an app defines how a product/app is performing or behaving as compared to its expected behavior" \cite{nfr-dotnetcurry}}. Die Leistungsfähigkeit einer Anwendung setzt sich aus den Punkten \emph{Zeitverhalten}, \emph{Ressourcennutzung} sowie \emph{Kapazität} zusammen. Das Zeitverhalten wird vor allem durch die Reaktionszeit der Applikation geprägt. Es wird gemessen, wie schnell auf Benutzereingaben eingegangen werden kann. Eng verwand ist dabei auch der Begriff der \emph{Latenzzeit}, da dieser beschreibt, wie lange die Beantwortung einer Anfrage in der Praxis letztendlich dauert. Die Reaktionszeit dient hierbei als ein Threshold der nicht überschritten werden sollte. Typischerweise wird die Reaktionszeit pro Client festgelegt, es ist jedoch auch möglich, dies für eine Menge von mehreren Clients festzulegen. Ein Beispiel wäre, dass ein bestimmter Anteil der Interaktionen eine maximale Reaktionszeit von \emph{n} Sekunden festgelegt wird. Aber auch das zweite Unterkriterium der \emph{Resourcennutzung} darf nicht vernachlässigt werden, so dürfen beispielsweise bestimmte Kommunikationsschnittstellen nicht überlastet werden und diverse Connectionspools nicht überlaufen, da es sonst zu Timeouts kommen könnte. Die Kapazität beschreibt zum Beispiel die Anzahl von möglichen parallelen Anfragen oder wie viele Nachrichten übermittelt beziehungsweise vom System gespeichert werden können. 

Ein weiterer Unterpunkt, welchen man der Leistungsfähigkeit zuschreiben kann, ist der des \emph{Durchsatzes}. Dieser Begriff wird in der ISO Norm zwar nicht erwähnt, stellt hierbei jedoch eine weiteres Kriterium dar, gerade im Hinblick auf den Anwendungsfall der Banking-Anwendung. Die verarbeiteten Daten können sich hierbei auch auf verschiedenes beziehen. Hiermit kann zum Beispiel die zeitliche Aufteilung von Anfragen an eine API sowie deren Rückmeldung gemeint sein. Oder es ist die Rede einer bestimmten Anzahl von Nachrichten bezüglich eines Brokers, die durch das System gereicht werden. Es kann sich aber auch ganz banal auf die Anzahl der Datenbankanfragen etc. beziehen. Diese Art der Performanz wird in der Regel mittels spezieller Tools, wie zum Beispiel "\emph{Gatling}" oder "\emph{JMeter}" in sogenannten \emph{Performance} oder \emph{Load Tests} validiert. Alles in allem stellt die Leistungsfähigkeit mit ihren Subkategorien eine der wohl wichtigsten Kriterien dar.


\subsubsection{Skalierbarkeit \checkmark}
% \paragraph{Hardware}
% \begin{itemize}
%   \item je nach Anforderungen hoch oder herunterfahren
%   \item \emph{concurrent users} : Wie viele Benutzer verwenden zeitgleich die Applikation. I.d.R. 20 - 30 Prozent der Userbase. Kann auf 100 Prozent bei besonderem Event hochgehen
%   \item Zeitfaktor nicht vergessen, Applikation Skalierung sollte auch zeitlich gesteuert werden
%   \item \emph{vertikale Skalierung / scaling up} : Mehr CPUs / RAM fuer existierende Infrastruktur
%   \item \emph{hori Skalierung / scaling out} : mehr Server
%   \item vielleicht Bild einfuegen scale out vs scale up
%   \item cloud provider verwenden generell scale out
% \end{itemize}

% \paragraph{Software}
% \begin{itemize}
%   \item Bsp. Ladezeiten einer single page application zu hoch (z.B. Laden von Daten aus DB), scale out bringt hierbei nichts...
%   \item Performanz sollte von Anfang an bedacht werden
%   \item Frameworks sollten auf multithreading etc. ausgelegt sein, vor Verwendung einmal überprüfen
%   \item Bottlenecks früh bestimmen, Legacy Libs eventuell austauschen
%   \item Load Balancer sollte in irgendeiner Art vorhanden sein um Hardware Skalierung mit Software in Verbindung zu bringen
%   \item Ohne Session Management ist die Performance schlecht, gilt es ebenfalls im Vorwege zu prüfen
% \end{itemize}

Ein weiteres wichtiges Kriterium, das jedoch nur indirekt in der ISO-Norm 25010 Norm auftritt, ist die Skalierbarkeit des Systems\footnote{siehe "\emph{resource utilisatzion}" der Hauptkategorie "\emph{performance effeciency}"}. Bei der Beurteilung kommt gilt es in erster Linie zwischen dem Skalieren der \emph{Hardware} sowie der \emph{Software} zu unterscheiden \cite{nfr-dotnetcurry}. Die Hardwareskalierung könnte man grob dem Unterkriterium "\emph{Ressourcennutzung}" zuordnen. Denn in einer modernen containerisierten Cloud-Umgebung soll es möglich sein, die einzelnen Komponenten nicht nur auf einem Gerät beliebig zu skalieren, sondern, falls die aktuelle Hardware an ihre Kapaziätsgrenzen stößt, auch zusätzliche Hardwarekomponenten hinzuziehen können. Inwiefern dies automatisiert oder manuell geschieht, lässt sich lediglich fallabhängig bestimmen, es sollte jedoch evaluiert werden, ob dies generell ermöglicht wird. Metriken zum Ermitteln der Skalierungszeitpunkte könnten zum Beispiel die Anzahl der parallel arbeiten Benutzer der Applikation (engl. "\emph{concurrent users}"), die Latenzzeit oder die CPU Auslastung der beteiligten Maschinen sein. Relevant ist jedoch ebenfalls, dass eine Applikation nicht nur von aktiv eingehenden Ereignissen skaliert wird, sondern auch ein Zeitverhalten aufweist, wodurch eine selbstständige zeitabhängige Skalierung erfolgen kann. Dies macht den Skalierungsprozess robuster, da die Komponente dadurch etwas von seiner Umwelt abstrahiert werden kann (welche in der Regel durchaus fehlerbehaftet sein kann). 

Bei der Hardwareskalierung gibt es zwei wesentliche Arten, die \emph{vertikale} und die \emph{horizontale Skalierung}. Der Begriff der \emph{vertikalen Skalierung} (engl. "\emph{scale up}" Skalierung) beschreibt das Modifizieren der servereigenen Ressourcen. Dazu können zum Beispiel die Anzahl der CPU-Kerne oder der verfügbare Speicher gehören. Dieses Verfahren wird in monolithischen Strukturen mit älteren Systemen verwendet, die nicht darauf ausgelegt sind, sich auf mehrere Server zu verteilen. Dagegen steht der Begriff der \emph{horizontalen Skalierung} (engl. "\emph{scale out}" Skalierung), welcher gerade dieses Auslagern bestimmter Komponenten oder Prozessinstanzen auf neue Hardware beschreibt. Letzterer Ansatz wird in der Cloud-Technologie verfolgt und nicht nur auf unternehmensinternen Systemen, sondern auch großen \emph{public cloud} Dienstleistern wie zum Beispiel Amazon (AWS) oder Microsoft (Azure), verwendet.

Dennoch muss die Software auf eine Skalierung der Hardware ausgelegt sein. Manche Probleme lassen sich mit mehr Rechenperformance nicht lösen. Wenn beispielsweise die Übertragungszeiten bestimmter Kommunikationsschnittstellen einen Flaschenhals darstellt, ändert eine Skalierung hieran nichts. Alter Legacy-Code könnte ebenfalls Performanceeinbußen mit sich ziehen, ohne ein angebrachtes Session-Management wird das Skalieren der Hardware dieses Problem nicht lösen können. Diese Grundfunktionalitäten werden heutzutage jedoch von fast allen Frameworks standardmäßig mitgeliefert, dennoch gilt es dies im Vorwege zu validieren. 


\subsubsection{Kompatabilität \checkmark}
Dieses Hauptkriterium beschreibt, wie ausgeprägt die nebenläufige Verarbeitung des Systems ist. Ist es möglich, dass mehrere Komponenten gleichzeitig arbeiten können, ohne sich gegenseitig zu behindern? Gerade in einer containerisierten Umgebung ist dies zu ermitteln. Der Unterbegriff \emph{Ko-Existenz} definiert dieses Verhalten. Der zweite Unterbegriff der "\emph{Interoperabilität}" grenzt hierbei die Kommunikation von der Nebenläufigkeit ab und beschreibt inwiefern die verschiedenen Komponenten in der Lage sind untereinander Daten auszutauschen. Wie genau dieser Datenaustausch aussieht, kann sich von System zu System unterscheiden. Zusammenfassend lässt sich sagen, dass diese Kriterien in einer containerbasierten Anwendung zwar gelten müssen, sie allerdings dennoch derartig abstrakt gehalten sind, dass es schwieriger ist hier messbare Metriken zu generieren. Entweder das System arbeitet hinsichtlich dieser Kriterien fehlerfrei oder es ist fehlerbehaftet, einen messbaren Mittelweg gibt es nicht direkt.


\subsubsection{Zuverlässigkeit \checkmark}
% https://www.dotnetcurry.com/project-management/1462/non-functional-requirements-nfrs
% \cite{nfr-dotnetcurry}
% \begin{itemize}
%   \item High Availability
%   \item Angabe wie lange app garantiert laeuft (bspw. Prozentangabe pro Jahr)
%   \item Design for failure: Komponenten darauf ausgelegt, dass Ausfall einzelner Komponenten zu keinem Systemausfall fuehrt
%   \item accessibility: app ist nicht für die Allgemeinheit konzipiert worden
% \end{itemize}

Ein weiteres Hauptkriterium der ISO-Norm 25010 bezieht sich auf die \emph{Zuverlässigkeit} eines Systems. Es beschreibt die garantierte Laufzeit einer Applikation \cite{nfr-dotnetcurry}. Dies kann auf verschiedene Weisen festgehalten werden. Eine typische Angabe wäre zum Beispiel der Anteil der Tage im Jahr, Tage pro Monat, oder Stunden am Tag die ein Service ansprechbar ist. Allgemein lässt sich diese Angabe als Metrik der \emph{Verfügbarkeit} charakterisieren. In einer containerisierten Umgebung kommt es immer wieder zu Ausfällen einzelner Systeme, was es bei diesem Punkt besonders zu beachten gilt. Das Gesamtsystem soll hiervon jedoch unberührt bleiben. Dieses Prinzip wird in heutigen Systemen auch "\emph{Design for failure}" genannt \cite[Seite~267]{continuous-delivery}. 

Das Hauptkriterium setzt sich unter anderem aus dem Unterkriterium der \emph{Reife} zusammen. Hierbei sind diejenigen Anforderungen gemeint, die in einer normalen Prozessabarbeitungsphase ohne besondere Ereignisse gegeben sein müssen. Die Anforderungen können sich zum Beispiel auf die Anzahl der zu verarbeitenden Nachrichten oder der Komplexität der zu bewältigenden Aufgaben zur gängigen Betriebszeit handeln. Außerdem wird eine gewisse \emph{Fehlertoleranz} vom System erwartet. Um dies zu testen, genügt es bereits dokumentierte, allerdings Fehlerbehaftete, Benutzereingaben in einer Testumgebung zu tätigen und das Systemverhalten zu analysieren. Eine standardisierte Metrik gibt es auch hier nicht. Das letzte Unterkriterium der \emph{Zuverlässigkeit} stellt die \emph{Wiederherstellbarkeit} nach einem beschriebenen Fehlerfall dar, falls es doch einmal zu einem Ausfall einzelner Komponenten kommen sollte. Generell gilt auch dieses Hauptkriterium gibt Aufschluss über die Eignung gewisser technologischer Ansätze zum Arbeiten als Cloudkomponente, dennoch beschreibt sie die relevanten Umstände in manchen Teilen zu abstrakt, als das es Gegenstand dieser Thesis sein könnte.

\subsubsection{Irrelevante Themenfelder \checkmark}

% \begin{itemize}
%   \item Security (Injection, Broken Authentication, Cross Site Scripting etc.)
%   \item Nutzbarkeit (Benutzerfreundlichkeit, Browser Kompatabilität, Internationalisierung - Eingabesprachen)
% \end{itemize}

Weitere Hauptkriterien der ISO-Norm betreffen die \emph{Nutzbarkeit} sowie die \emph{Sicherheit} der Anwendung. Da der Fokus des Projekts aber darauf liegt die Skalierbarkeit und Performance des Systems zu testen, können diese Punkte jedoch vernachlässigt werden. Die Themengebiete der \emph{Wartbarkeit} sowie der \emph{Übertragbarkeit} sind in einer containerisierten Plattform zwar ebenfalls bedeutsam, wurden wegen ihrer schwierigen Messbarkeit allerdings im Rahmen dieser Thesis verworfen. 


\subsubsection{Zusammenfassung \checkmark}
Im letzten Abschnitt wurde auf die verschiedenen Kriterien der ISO-Norm 25010 eingegangen sowie einige weitere relevante Kriterien hinsichtlich der nicht funktionalen Anforderungen hinzugefügt. Hierbei wurde bezüglich der Anwendung der Kriterien auf den zu entwickelnden Prototypen bereits eine minimale Vorauswahl getroffen, wobei erst im nächsten Abschnitt eine letztendliche Festlegung der betrachteten Kriterien sowie deren genau Erfassung erörtert wird. Im Folgenden werden die wesentlichen Kriterien noch einmal zusammengefasst.

\begin{itemize}
	\item Lediglich \emph{Nicht funktionale Anforderungskriterien} für dieses Projekt von Bedeutung
	\item Leistungsfähigkeit
	\begin{itemize}
		\item Zeitverhalten (Reaktions- / Latenzzeit)
		\item Ermittlung von Bottlenecks
		\item Leistungsfähigkeit (Durchsatz / Latenzzeit)
	\end{itemize}
	\item Skalierbarkeit
	\begin{itemize}
		\item Evaluierung ob automatisiert oder manuell gesteuert werden kann
		\item Reaktion auf externe sowie interne Ereignisse
		\item Ermitteln welche Skalierungsart angebracht (\emph{scale out} gegenüber \emph{scale up})
		\item Ermitteln ob Skalierung überhaupt zielführend
		\item Zeitverhalten relevant
	\end{itemize}
	\item Kompatabilität
	\begin{itemize}
		\item Ko-Existenz (Nebenläufigkeit überhaupt möglich)
		\item Interoperabilität (Kommunikation zwischen parallelen Komponenten)
	\end{itemize}
	\item Zuverlässigkeit
	\begin{itemize}
		\item Garantierte Laufzeit
		\item \emph{Design for failure} Prinzip erfüllt?
		\item Wiederherstellbarkeit
	\end{itemize}
	\item Irrelevante sowie nicht betrachtete Themenfelder
	\begin{itemize}
		\item Irrelevant
		\begin{itemize}
			\item Nutzbarkeit
			\item Sicherheit
		\end{itemize}
		\item out of scope
		\begin{itemize}
			\item Wartbarkeit
			\item Übertragbarkeit
		\end{itemize}
	\end{itemize}
\end{itemize}
