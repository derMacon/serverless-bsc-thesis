\section{Anforderungen an den Prototypen}
\label{sec:anforderungProto}
% \begin{itemize}
%   \item einmal als spring boot und einer weiteren variante mit einer cloud-native technologie -> hier wurde vorgegeben mit serverless zu arbeiten.
% \end{itemize}

Bei diesem Projekt soll sowohl eine Orchestrierungsplattform evaluiert als auch ein entsprechendes Framework hinsichtlich der Eignung im Kontext der Kernziele der Thesis verglichen werden (siehe Abschnitt \ref{ss:kernziele} \nameref{ss:kernziele}). 

Hinsichtlich der Skalierung soll es beispielsweise möglich sein, anhand festgelegter Regeln eine automatische \emph{horizontale} Skalierung bestimmter Komponenten vorzunehmen. Dieses Verhalten soll sowohl in hinterlegten Datensätzen als auch mithilfe eines eigens dafür eingerichteten Dashboards nachvollziehbar dargestellt werden. Auf welche Technologien sowohl bei der Skalierung als auch der Darstellung beziehungsweise bei der Berechnung der Metriken zurückgegriffen wird, wird vom Arbeitgeber nicht vorgegeben. Lediglich hinsichtlich der Komponenten zur Verarbeitung der Businesslogik wurde eine Vorauswahl getroffen. 



\subsection{Festlegung eines fiktiven Workflows}
\label{ss:fiktiverWorkflow}

Der Prototyp soll eine bereits bestehende Applikation nachbilden, welche die Zahlungsabwicklung sogenannter Echtzeitüberweisungen durchführt. "\emph{Die Echtzeitüberweisung (englisch Instant Payment) ist eine Zahlungsart, bei der Guthaben innerhalb weniger Sekunden dem Empfänger final gutgeschrieben werden. Inzwischen gibt es in zahlreichen Ländern weltweit Echtzeitzahlungssysteme. Im einheitlichen Euro-Zahlungsverkehrsraum, dem sogenannten Sepa-Raum, gibt es seit dem 21. November 2017 einen entsprechenden Standard: Die Sepa Instant Payments (SCTInst) sind 24 Stunden an 365 Tagen im Jahr verfügbar. Die Gutschrift muss in maximal 10 Sekunden erfolgen, faktisch werden die meisten Transaktionen allerdings in weniger als 3 Sekunden durchgeführt}" \cite{instpay-def}.

Da der Fokus auf der Untersuchung der Start-up-Zeit der Komponenten liegt, wird lediglich eine minimale, beispielhafte Implementierung erfolgen, welche die Arbeitsschritte der eigentlichen Applikation vereinfacht darstellen soll. Es soll im Rahmen dieser Arbeit eher als ein \emph{proof of concept} gelten. Allerdings werden im System konkrete Nachrichten im XML Format vermittelt, welche einer XSD-Spezifikation folgen wie sie im realen Umfeld ebenfalls genutzt wird (siehe Listing \ref{lst:paymentXml} \nameref{lst:paymentXml}).

\begin{minipage}{\linewidth}
\begin{lstlisting}[style=xmlStyle,caption={Payment Format},label=lst:paymentXml]
  <?xml version="1.0" encoding="UTF-8"?>
  <Document xmlns="urn:iso:std:iso:20022:tech:xsd:pain.001.001.09">

    ...

    <DbtrAcct>
      <Id>
          <IBAN>AT331200000696200104</IBAN>
      </Id>
    </DbtrAcct>
    <Cdtr>
      <Nm>DE NAME</Nm>
      <PstlAdr>
          <Ctry>DE</Ctry>
          <AdrLine>Point Courrier 201</AdrLine>
          <AdrLine>IT 91191 Gif sur Yvette</AdrLine>
      </PstlAdr>
    </Cdtr>

    ... 

</Document>
\end{lstlisting}
\end{minipage}


Sobald eine neue Nachricht eingetroffen ist, sollen drei Arbeitsschritte ausgeführt werden:

\begin{enumerate}

  \item Es soll geprüft werden, ob das eingegangene XML der in den Metainformationen angegebenen XSD-Spezifikation folgt. Wenn dies nicht der Fall sein sollte, wird die Nachricht zwar bestätigt (engl. \emph{acknowledged}), sodass sie aus der Eingangsqueue im Message Broker entfernt, allerdings bei der weiteren Verarbeitung ignoriert wird.

  \item Falls es sich um valides XML-Format handelt, wird ein Feld aus dem XML-Inhalt ausgelesen.

  \item In einem letzten Schritt wird das extrahierte Element in eine Datenbank geschrieben, damit auch eine Persistenz-Operation in die Verarbeitungszeit einfließt.

\end{enumerate}

\subsection{Artefaktbasierte Technologie}
Wie bereits angedeutet, wird die aktuell laufende Java-Enterprise Applikation mit einer Implementierung basierend auf dem moderneren Spring Boot Framework ersetzt. Spring Boot bietet im Kern eine sehr ähnliche Funktion und kann in gewisser Hinsicht als eine modernere Version des JEE Standards angesehen werden. Der Austausch ist vor allem hinsichtlich der zu gewinnenden Messwerte / Ergebnisse sinnvoll, um einen aktuelleren Referenzpunkt bezüglich der service-basierten Struktur zu erlangen.

\subsection{Skriptbasierte Technologie}

% \begin{itemize}
%   \item  4.2.2 spring boot 4.2.3 serverless -> so bekommt der prof schon beim draufgucken auf das inhaltsverzeichnis die story mit….
% \end{itemize}

Um bezüglich des Spring Boot Frameworks einen sinnvollen Vergleichspunkt anzusetzen, wird dem eine Skript-Technologie gegenübergestellt, da diese im \emph{Cloud Native} Bereich ebenfalls sehr häufig verwendet werden. "\emph{Eine native Cloud-Anwendung (NCA) ist ein Programm, das speziell für eine Cloud-Computing-Architektur entwickelt wurde. NCA nutzen die Vorteile von Cloud-Computing-Frameworks, die aus lose gekoppelten Cloud-Services zusammengesetzt sind.}" \cite{def-nca}. Mit dieser doch abstrakt gehaltenen Definition sind hinsichtlich der verarbeitenden Komponenten in erster Linie die modernen Skript-Frameworks gemeint. Hierbei existieren mehrere Alternativen, wo es seitens des Unternehmens ebenfalls keinerlei genaue Vorgaben hinsichtlich des spezifischen Frameworks beziehungsweise der zu nutzenden Technologie gab. Um allerdings ein möglichst repräsentatives Bild zu schaffen, wurde hierbei das Node.js Backend-Framework ausgewählt, da dieses als eines der am weitest verbreiteten Frameworks in diesem Bereich gilt. Sowohl die Node.js als auch Spring Boot Komponenten sollen jeweils die beschriebenen Arbeitsschritte implementieren.


\section{Anforderungen an die Containerplattform / Orchestrierungsplattform}
\label{sec:anforderungPlattform}

Unter dem Begriff des "emph{Containers}" wird in der Entwickler-Community meist ein "\emph{Docker-Container}" verstanden. Allgemein beschreibt dieser Begriff in der Softwareentwicklung ein abstraktes Konzept auf Betriebssystem-Level zur Virtualisierung oder Prozessisolation. Es gibt zahlreiche Implementierungen wie beispielsweise CoreOS's "\emph{rkt}" oder Microsoft's "\emph{Hyper-V}". Docker stellt hierbei lediglich eine weitere Implementierung dieser Technologie dar \cite[Seite~63 ff.]{continuous-delivery}. Dennoch hat sich Docker gegenüber anderen Implementierungen vor allem über die einfache Benutzerführung sowie die zentralisierten Mechanismen zum \emph{Teilen}, \emph{Pullen} und \emph{Pushen} durchgesetzt. Die generelle Funktionsweise sowie die Vorteile von Docker wurden bereits ausführlich erläutert. Da die Docker Technologie von allen vorgestellten Implementierungen am weitesten verbreitet ist, soll diese auch im Prototypen Verwendung finden. 

Eine Containerplattform zeichnet sich allerdings neben der genutzten Implementierung über weitere Komponenten aus. Eine der Wichtigsten stellt hierbei der Orchestrator dar. "\emph{This component is responsible for starting, stopping, and managing the container processes. This technology is often referred to as container infrastructure as a service (CIaaS), and in the Docker ecostystem this is typically provided by Docker Swarm or Kubernetes}" \cite[Seite~64 ff.]{continuous-delivery}. Hierbei wird auch die Portiblität sowie die Reproduzierbarkeit eines Systems als eine wesentliche Anforderung vorausgesetzt \cite[Kapitel Orchestration]{docker-doc}. Da Kubernetes im Unternehmen bereits Anwendung findet, wurde sich hierbei auf Docker Swarm festgelegt, um ein Demo-Projekt auszuarbeiten, an dem sich in Zukunft andere Projekte orientieren können. Swarm grenzt sich gegenüber anderen Technologien vor allem durch den nativen Support innerhalb des Docker Ökosystems ab. Man benötigt keine weiteren externen Tools, sofern eine Docker Installation vorliegt \cite[Seite~10 ff.]{soppelsaswarm}. Desweiteren ist es möglich Images in einem skalierten System zu deployen ohne weitere Anpassungen am Image selbst vornehmen zu müssen. Diese Images können außerdem in Clustern organisiert werden, welche direkt über ein alternatives Tool namens "\emph{Docker Compose}" konfiguriert werden können.

"\emph{Docker Compose allows the declarative specification of applications/services and associated dependencies and data stores. This pattern does allow for the flexible execution of a collection of dependent services on a local development machine}" \cite[Seite~173]{continuous-delivery}. Um diese Spezifikation auch in einer produktiven Umgebung auszuführen, wird auf einen Orchestrator wie zum Beispiel \emph{Docker Swarm} zurückgegriffen. Das Swarm Tool wird hierbei massiv in Produktions-Umgebungen eingesetzt, da es in der Lage ist Tausende von Containern zeitgleich zu verwalten und über einen dezentralen Discovery Service anzusteuern. 

Da es im Cluster vermehrt zur Ausführung mehrerer Instanzen des gleichen Images kommen kann, ist es nicht mehr möglich einen Service mit einer spezifischen IP-Adresse zu versehen. Bei untereinander abhängigen Services braucht es einen Kommunikationsmechanismus zwischeneinander. Dieser wird durch einen "\emph{Discovery Service}" organisiert. Ein solcher Service ist neben dem Vermitteln von Anfragen auch in der Lage Konfigurationsänderungen der einzelnen Services im System zu organisieren sowie die Verfügbarkeit der jeweiligen Instanzen zu prüfen \cite[Seite~45 ff.]{soppelsaswarm}.

\paragraph{Zusammenfassung}
\begin{itemize}
  \item Wesentliche Anforderungen Container
  \begin{itemize}
    \item Portabilität
    \item Reproduzierbarkeit
  \end{itemize}
  \item Wesentliche Anforderungen Orchestrator
  \begin{itemize}
    \item Automatisierte Wartung 
    \begin{itemize}
      \item Container Updates
      \item Austausch fehlerhafter Container
    \end{itemize}
    \item ermöglicht Skalierung bestimmter Services
  \end{itemize}
\end{itemize}


\section{Anforderungen an den Lasttest}
Es soll möglich sein, das System in einem einheitlichen Format mit Nachrichten zu versorgen. Hierfür benötigt man eine Benutzerschnittstelle, die es ermöglicht dem Benutzer möglichst aussagekräftige Befehle mit minimalen Konfigurationsaufwand zur Verfügung zu stellen. Diese Befehle müssen anschließend intern wiederum in detaillierte Nachrichten umgewandelt werden, welche durch das System bearbeitet werden können. Hierfür gibt es die Möglichkeit einer Benutzeroberfläche im Browser oder der Festlegung eines Formats im Body einer Http-Anfrage an eine REST-API. Eine Skalierung auf mehrere Systeme sollte einmal testweise erfolgen, für die Generierung der Metriken ist dies allerdings contraproduktiv, da es die Ergebnisse verfälschen könnte. Diese Verfälschung könnte auftreten, da es dem Design der Orchestrierungsplattform geschuldet ist, dass der Anwender wenig Einfluss auf die Ressourcenzuteilung hat. Hierbei kann es passieren, dass eine leistungsschwächere Maschine deutlich weniger Anfragen zugewiesen bekommt. Dies könnte man zwar dadurch umgehen, dass man zwei exakt gleichbestückte Server für den Lastentest verwendet. Hierbei würden im Nachhinein allerdings im besten Fall die gleichen Ergebnisse erlangt werden, wie bei einem Testlauf auf einer einzelnen Maschine.

\section{Anforderungen die Visualisierung und das Monitoring zur Unterstützung der Auswertung}
Es soll möglich sein, Messwerte automatisch vom System generieren zu lassen. Dazu müssen die Datensätze persistent hinterlegt werden, um auch im Nachhinein nachvollziehen zu können wie die Metriken entstanden sind. Außerdem muss eine grafische Aufarbeitung erfolgen. Diese Visualisierung soll in Echtzeit oder einem zeitlich festgelegten Intervall aktualisiert werden können. Bezüglich des genauen Werkzeugs werden keinerlei Vorgaben gegeben, um dem Benutzer jedoch jeglichen Installationsaufwand zu ersparen wäre eine webbasierte Darstellung von Vorteil.
