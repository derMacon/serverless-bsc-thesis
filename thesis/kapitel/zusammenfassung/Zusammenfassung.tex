\chapter{Zusammenfassung}

Nachdem im letzten Abschnitt sämtliche Messwerte vorgestellt, analysiert und beurteilt wurden, folgt nun eine Zusammenfassung der gesamten Thesis.

Die Idee und die Umsetzung der Arbeit erfolgte in Zusammenarbeit mit der DPS Engineering
Gmbh. Hierbei handelt es sich um ein europaweit tätiges Software- und Consultingunternehmen für
die Finanz- und Retailbranche. Das Unternehmen möchte in Zukunft auf moderne Technologien setzen, um ihre Plattform für die Echtzeitüberweisungen performanter und ressourcensparender zu gestalten. Da das Unternehmen im Banking Bereich tätig ist, stellt außerdem eine hohe Verfügbarkeit der Komponenten
eines der wesentlichen Kernziele dar. Auf die neuen Technologien bezogen bedeutet dies, dass es zu
ermitteln gilt, wie viel Zeit ein Skalierungsprozess in einem orchestrierten Komponentenstack im
Detail braucht. Um festzustellen, wie gut die jeweils betrachtete Backend-Technologie im Endeffekt für den Betrieb in einer containerbasierten Anwendung tatsächlich geeignet ist, wurde ein fiktiver Workflow mithilfe eines Komponentenstacks implementiert, der in der Lage ist, verschiedene Lastszenarien abarbeiten zu können. Hierbei wurden im späteren Verlauf austauschbare Komponenten implementiert, um eine Gegenüberstellung anhand erhaltener Messwerte zu ermöglichen.

Es folgte ein kurzer Einblick in die aktuelle Produktivumgebung und die damit verbundene monolithische Struktur. Es wurde ebenfalls auf die Probleme dieser Architektur eingegangen, welche unter anderem als Motivation der Thesis betrachtet werden können.

Nachdem die Kernziele im Detail erläurtert wurden, erfolgte eine Festlegung sämtlicher Anforderungen für das Projekt. Hierbei wurden diese für die verschiedenen Teile des Projekts gesondert festgelegt. Hinsichtlich der Daten zur Messung des Startup-Verhaltens von Containern wurde auf die ISO Norm 25010 zurückgegriffen. Diese stellt einen Kriterienkatalog zu qualitativen Anforderungen an Softwareprodukte dar. Sie beinhaltet unter anderem eine Beschreibung der \emph{Leistungsfähigkeit}, \emph{Skalierbarkeit}, \emph{Kompatabilität} und \emph{Zuverlässigkeit} eines Produkts. Die Festlegung der zu betrachtenden Anforderungen erfolgte im nachfolgenden Abschnitt. Anschließend wurden die Anforderungen an den Prototypen formuliert, hierbei wurde insbesondere ein fiktiver Workflow festgelegt. Dieser orientiert sich an der Ablauflogik des Softwareprodukts innerhalb der Produktivumgebung. Primär erfolgt eine Überprüfung, ob es sich bei dem Inhalt einer eingehenden Nachricht um valides XML handelt (XSD-Konformität), anschließend wird ein Feld aus dem XML ausgelesen und in einer Datenbank hinterlegt. Danach folgten die Anforderungen Containerplattform sowie die Orchestrierungsplattform, wobei festgelegt wurde, dass in erster Linie die Portabilität und die Reproduzierbarkeit für das Arbeiten mit Containern von Bedeutung sind, während die automatische Wartung sowie die Skalierung für die Orchestrierungsplattformen am wichtigsten sind. Bezüglich der Anforderungen des Lasttests wurde auf eine benötigte Benutzerschnittstelle sowie die Hinterlegung der Daten in einer Persistenzschicht eingegangen. Die Anforderungen für das Monitoring und der Darstellung der Daten bestehen aus dem Visualisieren der zeitlichen Zusammenhänge und der Persistenz der Daten in einer internen Datenbank.

Nachdem im letzten Abschnitt die möglichen Qualitätsmerkmale erläutert wurden, erfolgte nun eine Festlegung auf die zu betrachtenden Merkmale. Hierbei wurden die \emph{Leistungsfähigkeit} sowie die \emph{Skalierbarkeit} gewählt. Es wurde außerdem darauf eingegangen, auf welche Weise diese zu testen sind. Hierzu wurde die Pipeline in mehrere Etappen unterteilt, zu denen Timestamps erzeugt werden sollen, um möglichst aussagekräftige Ergebnisse zu erlangen. 

Im Anschluss hieran erfolgte die Beschreibung der Implementierung des Prototypen. Es wurde auf das zugrunde liegende Schichtenmodell, die Methodik des Deployments sowie die Ablauflogik auf Komponentenbasis eingegangen. 

Am Ende der Thesis folgte eine Ergebnisanalyse. Hierbei wurden die erhaltenen Messwerte im Detail erläutert. Hierbei wurden zwei Lasttests durchgeführt. Der Erste gibt Payment-Nachrichten in das System. Hierbei muss das System selbstständig in der Lage sein eine entsprechende Skalierung vorzunehmen. Im zweiten Test wird die Skalierung als Reaktion auf direkte Anweisungen des Benutzers vorgenommen. Die Ergebnisse hierbei zeigen, dass es hinsichtlich der Initialisierungsdauer der Komponenten mit Node.js als implementierende Technologie einen deutlichen Vorteil gegenüber der Spring-Boot-Technologie zu verzeichnen gibt. Die Latenzzeit im gesamtdurchschnittlichen Vergleich zeigt bei der Node.js-Technolgie beispielsweise einen Wert von 38.4 Sekunden, während dieser Wert bei der Spring Boot Technologie bei 61.8 Sekunden liegt. Auch bei einer feingranulareren Untersuchung hinsichtlich der Burstgröße oder der einzelnen Containeranzahlen ergibt sich ein ähnliches Bild. Dennoch gilt es noch hervorzuheben, dass die Spring Boot Technologie einen deutlichen Performancevorteil hinsichtlich der reinen Verarbeitungszeit der Nachrichten aufweist. Die Node.js-Komponente benötigt im Schnitt 388 Millisekunden um eine Nachricht zu verarbeiten, während dieser Wert bei Spring Boot bei 29 Millisekunden liegt. 

Im darauf folgenden Abschnitt wurden diese Werte noch einmal näher analysiert und es wurden mögliche Begründungen für das gemessene Verhalten aufgezeigt. Die lange Startzeit der Spring-Boot-Komponente lässt sich beispielsweise unter anderem auf die komplexe Konfiguration des Frameworks und der damit verbunden Bean-Instanzen zurückführen. Die performantere Verarbeitungsgeschwindigkeit lässt sich dagegen vor allem dadurch begründen, dass es sich bei der verwendeten Programmiersprache des Spring-Boot-Frameworks um eine kompilierte Sprache handelt.